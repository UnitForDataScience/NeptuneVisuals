For p  q let R be a p - qx p-dimensional matrix having orthonormal columns that span the orthogonal compliment of the space spanned by the columns of R. Because the columns of any p x d-dimensional matrix can we written in terms of the basis given by the columns of R and R we have W  RQ  R A for matrices Q and A. Inserting this form into fW and using RT R  0 and XR  0 we findf dWTh 14 jjX - BQTRTjj2 th jjATAjj2 .

This may be because a certain set of OTUs may allow good prediction of a columns of B even if these OTUs do not explain much of the overall variability in the OTU table e.g.

While this separation is useful in showing that OTUs vary systematically across groups investigators often wish to know which OTUs contribute most to this separation.

In we show the 11 OTUs that were selected to be on the list of the top 5 OTUs foreach method along with the variability explained by that OTU and its rank by each method.

We found that both orthogonal approaches and unconstrained decomposition were in broad agreement similar model sums of squares similar OTUs identified as impor- tant while unconstrained regression behaved very differently identifying very different OTUs as important and having a small model sum of squares.

These pipelines produce OTU counts abundances that can be summarized in a data matrix X here we take the rows to correspond to observations and the columns to species or OTUs.

Whatever scaling and centering is applied the data matrix X can always be written using the singular value decompo- sition SVD asX 14 LSRTd1Thwhere L is a n x q matrix with orthonormal columns S is a q x q diagonal matrix having posi- tive entries and R is a p x q matrix with orthonormal columns where q is rank of X.

If we are willing to measure similarity between observations using D  XXT then the columns of L com- prise the coordinates of the observations in a principal components analysis or a principal coordinates analysis PCoA if count data in X have been scaled and centered as described above since the columns of L are also the principal components of XXT.

Note that if we are only inter- ested in a subset of the columns of B we can replace B by Bd the n x d matrix that contains the d columns of interest.

Note that Lemma 1 implies that mini- mization of is equivalent to minimization of jjLS - BQTjj2 for q x d--dimensional matrix Q which implies we can find a unique minimizer even when p  n since q S minp n. By direct optimization we find that if the columns of B are orthogonal the minimizer of isWdu  VduDdu 14 XTBd6Thgiven Wdu Ddu and Vdu are determined by the norms of the columns of Wdu.Unlike  optimization of produces a family of solutions.

