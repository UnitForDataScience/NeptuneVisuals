For cuCLARK light the reducedTable 3 Classification speed for different sampling factors at species-level for the HiSeq dataset in terms of 106 sequencesmin and corresponding main memory consumptionTable 4 Classification speed comparison between CLARK light and cuCLARK light at species-level in terms of 106 classified sequencesminThe bottom row reports the speedup of cuCALRK light compared to CLARK light executed with 16 CPU threadsdatabase is smaller than 720 MB and leaves enough space for batch data even on graphics cards with only 1 GB of memory.

For MiSeq wgsim200 wgsim250 and fqIon Kraken using 16 threads is still 1.4-1.8 times faster than CLARK with the same number ofTable 1 Classification speed of CLARK Kraken and cuCLARK at species-level measured in terms of 106 classified sequences reads per minuteThe bottom two rows report the speedups between cuCLARK over CLARK and Kraken executed with 16 CPU threadsTable 2 Classification speed of CLARK Kraken and cuCLARK at genus-level measured in terms of 106 classified sequences reads per minuteThe two bottom rows report the speedups of cuCLARK over CLARK and Kraken executed with 16 CPU threadsthreads.

cuCLARK light is up to 6.6 times faster on a single GPU than CLARK light using 16 CPU threads.As our experiments have shown the classification speed of our program heavily correlates with the amount of available video RAM and the memory bandwidth.

cuCLARK has been executed on a Titan X for single GPU experiments.For cuCLARK we have decided to process the input files in 16 batches so the space required for each batch is small enough to leave most graphics memory for the database parts.

cuCLARK supports classification on a workstation with a single GPU and compute nodes withmultiple GPUs.Despite the differences in implementation CLARK and cuCLARK produce the same target scores for each input object.

Figure shows the database structure of cuCLARK.We use page-locked host memory to store the database in RAM to improve the transfer bandwidth to the graphics memory over the PCIe bus.

Next the sequence data of a batch is transferred to graphics memory for classification.Aside from higher transfer speeds the use of page- locked memory allows for batches to be processed asyn- chronously by the GPU.

This fast but small memory can be accessed simultaneously by all threads of a block for caching data from the global graphics memory or to store intermediate results.

The drawback of the limited amount of shared memory is that less blocks can be processed concurrently if they require too much memory each.

Future accelerator cards from the professional Tesla branch e.g the to be released Tesla P100 chip will feature 16 GB of high bandwidth stacked memory This novel memory type allows for significantly higher bandwidths in compar- ison to current GDDR5 and GDDR5X modules.

