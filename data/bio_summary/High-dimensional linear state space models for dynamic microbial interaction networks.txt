It is advantageous to perform variable selections to determine the zero elements of A while we can estimate the non-zero elements at the same time.It is known that from the Markov property of the state space model the joint likelihood for complete data for the SSM can be written asPdyTh 14 Pdx1ThTt142Pdxtjxt-1ThTt141PdytjxtThd3Thwhere th  A Q R m S. For the linear SSM  the joint log-likelihood of complete data can be expressed aslog PdyTh14 -Tt141d 12yt - xt0R-112yt - xtTh -log jRjT-t1421d2 12xt - Axt-10Q-112xt - AxtTh -T - 12log jQjd4Th10 -11- 2 12x1 - m S 12x1 - m - 2 log jSj - Tp log d2pThIn the following subsections we propose the Expectation-Regularization-Maximization ERM algorithm to simultaneously determine the zero-elements and estimate the non-zero elements of A based on the maximum likelihood principle.Expectation-Regularization-Maximization ERM algorithmWhen the SSM parameters are known the Kalman filter and smoother can be used to estimate the hidden states .

The estimates of Q R m S can be obtained by maximizing the expected conditional likeli- hood  with given sufficient statistics from the E step and A aL from the R step i.e.m 14 xT S 14 dxx0ThT - xTxT0 d19Th1 XT111 1 1 XTT T The row-based ERM algorithmNote that in the above R Step implementation a is a p2 x 1 vector and Z is a p2 x p2 matrix.

wTThe 14 vecdeThd13Thwhere vec is the stack operator and is the Kronecker product ai is the ith row vector of A a is the vectorized A which is a p2 x 1 vector e is a pT - 1 x 1 vector that represents mea- surement errors.The matrix-based ERM algorithmIn the standard EM algorithm for linear SSMs the estimate of A the system matrix can be obtained by maximizing the conditional expectation of the likelihood function  which is equivalent to minimizingGdaTh 14 EXZjYydr-1ThfdX - ZaTh0dX - ZaThgin vectorized notations.

As suggested we applied and started the ERM algorithm from the R step to the 100 simulated data sets M  100.To evaluate the performance of the proposed ERM algorithm for variable selection we cal- culated the false positive rate FP and false negative rate FN of A aL byFP 14 P 1 ijij da Th  FN 14 P 1 ijij 1da Th d23Thwhere P is the number of nonzero elements and N is the number of zero elements in A and 1fgdaijTh is an indicator function.

In addition the state vari- ables xt and their sufficient statistics functions of xt required for estimating unknown parameters in the R and M step are also estimated through the Kalman filter and smoother at this step.R Step the L1 regularization or the adaptive LASSO method is employed to obtain the esti- mate of the sparse system matrix A denoted by Ar.M Step the MLE of other model parameters th  Q R m S denoted by thr is obtained by maximizing the conditional expectation of likelihoodGdyjydr-1Th AdrThTh 14 Edr-1Th r d log PdyThThd6ThFor the standard SSM the EM algorithm starts from the E Step for a given initial value of the system matrix A based on the prior knowledge of the dynamic system.

Matrices Vt in and dVt-1Th-1 in can be expressed alternatively asttt 14 12C0R-1C th dVt-1Th-1-1dVt-1Th-1 14 Q-1 - Q-1A12A0Q-1A th dVt-1Th-1-1A0Q-1Note that the inverse of the matrix in brackets above are of the same form B0DB  D-1-1 where D is a symmetric n x n matrix B is an arbitrary n x n matrix and D is a diagonal matrix with diagonal elements d1 .

It was shown in  that under mild assumptions A is a zero-consistent esti-mator of A using w ijvariable selection.14 jA j-1 as weight for adaptive LASSO can achieve oracle efficiency inOnce a is estimated by adaptive LASSO the system matrix A aL can be easily reconstructed by reshaping the p2 x 1 vector a into a p x p matrix.

This is equivalent to applying the LASSO method to the restruc- tured state equation in  in a matrix pseudo-regression formX 14 Za th ee  Nd0 I QTh 14 Nd0 s2  IThd16ThWe call this a pseudo-regression model since X and Z are state variables estimated from SSMs instead of measured response variables and covariates in a standard regression model.

The true system matrix for the SSM in this simulation experiment is a 41x41 system matrix A.

Denote Xi as the ith row of X ai as the ith row of A and ei as the ith row of e. The adaptive LASSO estimate of A can be obtained by equivalently applying the adaptive LASSO to a linear pseudo-regression modelXi 14 Zai th eid21Thwherex11x12.

